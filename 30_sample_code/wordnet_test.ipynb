{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latest-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n",
      "3.5\n",
      "<class 'spacy.lang.en.English'>\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)\n",
    "print(nltk.__version__)\n",
    "print(English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "# https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.tokens import Token\n",
    " \n",
    "from spacy.language import Language\n",
    "\n",
    "# 形態素解析で特定した品詞を元に、辿るべき上位語を特定する。\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    "\n",
    "def get_hypernyms_all(synset, nup):\n",
    "    niter = 0\n",
    "    synset2 = synset.name()\n",
    "    synset_list = [synset2]\n",
    "    while True:\n",
    "        niter += 1\n",
    "        try:\n",
    "            print(synset2)\n",
    "            synset2 = get_hypernyms_iter(synset, niter=niter)\n",
    "            synset_list.append(synset2)\n",
    "        except:\n",
    "            break\n",
    "    return synset_list[nup]\n",
    "\n",
    "def get_hypernyms_iter(synset, niter=1):\n",
    "    synset2 = synset\n",
    "    for iiter in range(niter):\n",
    "        synset2 = get_hypernyms(synset2)\n",
    "    return synset2.name()\n",
    "\n",
    "def get_hypernyms(synset):\n",
    "    return synset.hypernyms()[0]\n",
    "\n",
    "class WordnetPipeline(object):\n",
    "    def __init__(self, nlp):\n",
    "#     def __init__(self):\n",
    "        Token.set_extension('synset', default=None)\n",
    "        Token.set_extension('hypernym', default=None)\n",
    " \n",
    "    def __call__(self, doc):\n",
    "        for token in doc:\n",
    "            wn_tag = penn_to_wn(token.tag_)\n",
    "            if wn_tag is None:\n",
    "                continue\n",
    " \n",
    "            ss = wn.synsets(token.text, wn_tag)[0]\n",
    "            token._.set('synset', ss.name())\n",
    "            if (wn_tag == 'n'):\n",
    "                nup = -1\n",
    "            else:\n",
    "                nup = -1\n",
    "            token._.set('hypernym', get_hypernyms_all(ss, nup))\n",
    "#             token.set_extension()\n",
    " \n",
    "        return doc\n",
    "\n",
    "# @English.factory('wn_synsets')\n",
    "@Language.factory('wn_synsets')\n",
    "def wn_synsets(name, nlp):\n",
    "    return WordnetPipeline(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "veterinary-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WordnetPipeline at 0xffff71538bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "nlp.add_pipe('wn_synsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris.n.01\n",
      "be.v.01\n",
      "amazing.s.02\n",
      "capital.n.01\n",
      "assets.n.01\n",
      "possession.n.02\n",
      "relation.n.01\n",
      "abstraction.n.06\n",
      "entity.n.01\n",
      "france.n.01\n",
      "wish.v.02\n",
      "desire.v.01\n",
      "tennis.n.01\n",
      "court_game.n.01\n",
      "athletic_game.n.01\n",
      "game.n.01\n",
      "activity.n.01\n",
      "act.n.02\n",
      "event.n.01\n",
      "psychological_feature.n.01\n",
      "abstraction.n.06\n",
      "entity.n.01\n",
      "very.r.01\n",
      "much.r.01\n",
      "Paris NNP PROPN paris.n.01 paris.n.01\n",
      "is VBZ AUX be.v.01 be.v.01\n",
      "the DT DET None None\n",
      "awesome JJ ADJ amazing.s.02 amazing.s.02\n",
      "capital NN NOUN capital.n.01 entity.n.01\n",
      "of IN ADP None None\n",
      "France NNP PROPN france.n.01 france.n.01\n",
      ". . PUNCT None None\n",
      "I PRP PRON None None\n",
      "like VBP VERB wish.v.02 desire.v.01\n",
      "tennis NN NOUN tennis.n.01 entity.n.01\n",
      "very RB ADV very.r.01 very.r.01\n",
      "much RB ADV much.r.01 much.r.01\n"
     ]
    }
   ],
   "source": [
    "text = \"Paris is the awesome capital of France. I like tennis very much\"\n",
    "\n",
    "for token in nlp(text):\n",
    "    print(token, token.tag_, token.pos_, token._.synset, token._.hypernym)\n",
    "# print([token._.synset for token in nlp(text)])\n",
    "# print([token.tag_ for token in nlp(text)])\n",
    "# print([token.pos_ for token in nlp(text)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
